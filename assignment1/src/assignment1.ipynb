{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assignment 1\n",
    "\n",
    "> Joshua Schmidt\n",
    "\n",
    "_I pledge my honor that I have abided by the Stevens Honor System_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this assignment was to categorize using Logistic Regression and multi-layer perceptrons the author a given text is written by. There are three categories that the text can be placed into (based on the author's name): \"Fyodor Dostoyevsky\", \"Arthur Conan Doyle\", and \"Jane Austen\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivation iframe does not show up automatically. You will need to run the cell to view the pdf below. Otherwise you can view the pdf by opening the `proof/assignment_1_derivation.pdf` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"800\"\n",
       "            src=\"../proof/assignment_1_derivation.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f2bf145ef50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"../proof/assignment_1_derivation.pdf\", width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first code I wrote includes utility functions. In this case, the `utils.py` file contains `get_glob`, used to get files based off of a path relative to the root directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "utils functions (utils.py)\n",
    "\"\"\"\n",
    "\n",
    "from glob import glob\n",
    "from os.path import abspath, join\n",
    "from loguru import logger\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_glob(glob_rel_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    get glob file list for given path\n",
    "    \"\"\"\n",
    "    logger.info(\"getting files using glob\")\n",
    "    complete_path: str = join(\n",
    "        abspath(join(Path(__file__).absolute(), '../..')), glob_rel_path)\n",
    "    files = glob(complete_path)\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next file contains an object outlining a Book object, along with metadata about each book. An enumeration is used to define each book, and dictionaries are used to link the enum to the class name and a StartEnd object. This object contains the start and end line numbers for the useful lines. Without these start and end line numbers, it would be difficult to exclude parts of the book like the Table of Contents, for example, which are not paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "classification type (books.py)\n",
    "\"\"\"\n",
    "\n",
    "from enum import Enum\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class BookType(Enum):\n",
    "    \"\"\"\n",
    "    Enum to store nlp types\n",
    "    \"\"\"\n",
    "    dostoyevsky = \"dostoyevsky\"\n",
    "    doyle = \"doyle\"\n",
    "    austen = \"austen\"\n",
    "\n",
    "\n",
    "class StartEnd:\n",
    "    \"\"\"\n",
    "    start and end lines for book\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, start: int, end: int):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "\n",
    "start_end_map: Dict[BookType, StartEnd] = {\n",
    "    BookType.dostoyevsky: StartEnd(186, 35959),\n",
    "    BookType.doyle: StartEnd(62, 12681),\n",
    "    BookType.austen: StartEnd(94, 80104),\n",
    "}\n",
    "\n",
    "class_map: Dict[BookType, str] = {\n",
    "    BookType.dostoyevsky: 'Fyodor Dostoyevsky',\n",
    "    BookType.doyle: 'Arthur Conan Doyle',\n",
    "    BookType.austen: 'Jane Austen',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cleaning function, each file is read, processed, and saved to a Pandas DataFrame for later use. The glob utility function mentioned earlier is used to get the file paths, and the lines are read one by one using a `while True` loop. All text is converted to lower case, but the text retains this punctuation. The reasoning behind this is that some authors may use more quotes because they have more dialogue in their stories, such as in Sherlock Holmes, and therefore the punctuation would help with classification. However, upper-case characters will most likely not help in distinguishing one author's text from another. Additionally, subsequent lines that include quotes, such as back-and-forth dialogue, are considered part of the same paragraph, and are treated as such by this algorithm. Lines that start with \"Chapter\" or \"ADVENTURE\" are excluded, and books stop when either the stop line number is reached or ending strings are found (\"the end\" or \"end of this project gutenberg book\"). This makes the cleaning fairly resilient to processing new inputs. At the end of the cleaning, a sample of the dataframe is outputted to show some of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "data clean (clean.py)\n",
    "\"\"\"\n",
    "\n",
    "from os.path import basename, splitext\n",
    "from typing import Optional, List\n",
    "from utils import get_glob\n",
    "from variables import data_folder, paragraph_key, label_key, random_state, class_key\n",
    "from loguru import logger\n",
    "from books import BookType, start_end_map, class_map\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "title_split: str = 'title: '\n",
    "author_split: str = 'author: '\n",
    "\n",
    "start_book: str = 'start of this project gutenberg ebook'\n",
    "the_end: str = 'the end'\n",
    "end_book: str = 'end of this project gutenberg ebook'\n",
    "\n",
    "chapter: str = 'Chapter '\n",
    "adventure: str = 'ADVENTURE '\n",
    "multi_quote_identifier: str = '\"'\n",
    "\n",
    "min_line_len: int = 6  # line discarded if less than this number of characters\n",
    "\n",
    "\n",
    "def clean() -> Tuple[pd.DataFrame, List[BookType]]:\n",
    "    \"\"\"\n",
    "    data cleaning\n",
    "    \"\"\"\n",
    "    data: pd.DataFrame = pd.DataFrame()\n",
    "    class_count: int = 0\n",
    "    label_list: List[BookType] = []\n",
    "\n",
    "    # preprocess data and construct examples\n",
    "    for file_path in get_glob(f'{data_folder}/*.txt'):\n",
    "        file_name: str = basename(splitext(file_path)[0])\n",
    "        logger.info(f'processing {file_name}')\n",
    "        title: Optional[str] = None\n",
    "        book_key: Optional[BookType] = None\n",
    "        book_started: bool = False\n",
    "        paragraphs: List[List[str]] = []\n",
    "        num_newline_count: int = 0\n",
    "        line_number: int = 0\n",
    "        with open(file_path, 'r') as current_file:\n",
    "            while True:\n",
    "                line = current_file.readline()\n",
    "                line_number += 1\n",
    "                line_lower_trim: Optional[str] = None\n",
    "                if line:\n",
    "                    line_lower_trim = line.lower().strip()\n",
    "                if not book_started and \\\n",
    "                    ((line_lower_trim is not None and line_lower_trim.startswith(start_book))\n",
    "                     or (book_key is not None and line_number >= start_end_map[book_key].start)):\n",
    "                    book_started = True\n",
    "                if line_lower_trim is None or line_lower_trim.startswith(end_book) \\\n",
    "                        or line_lower_trim == the_end or \\\n",
    "                        (book_key is not None and line_number >= start_end_map[book_key].end):\n",
    "                    # done with reading the file\n",
    "                    break\n",
    "                if not book_started:\n",
    "                    if title is None and line_lower_trim.startswith(title_split):\n",
    "                        title = line_lower_trim.split(title_split)[1]\n",
    "                        logger.info(f'title: {title}')\n",
    "                    if book_key is None and line_lower_trim.startswith(author_split):\n",
    "                        author: str = line_lower_trim.split(author_split)[1]\n",
    "                        logger.info(f'author: {author}')\n",
    "                        book_key = BookType(author.split(' ')[-1])\n",
    "                else:\n",
    "                    if len(line_lower_trim) < min_line_len or \\\n",
    "                            line.startswith(chapter) or line.startswith(chapter):\n",
    "                        num_newline_count += 1\n",
    "                    else:\n",
    "                        multi_line_quotes = line_lower_trim.startswith(multi_quote_identifier) \\\n",
    "                            and paragraphs[-1][0].startswith(multi_quote_identifier)\n",
    "                        if len(paragraphs) == 0 or \\\n",
    "                                (num_newline_count > 0 and not multi_line_quotes):\n",
    "                            paragraphs.append([])\n",
    "                        num_newline_count = 0\n",
    "                        paragraphs[-1].append(line_lower_trim)\n",
    "        if book_key is None:\n",
    "            raise RuntimeError('no book key found')\n",
    "        class_name = class_map[book_key]\n",
    "        logger.info(\n",
    "            f'number of paragraphs in class \"{class_name}\": {len(paragraphs)}')\n",
    "        data = pd.concat([data, pd.DataFrame({\n",
    "            paragraph_key: [' '.join(paragraph) for paragraph in paragraphs],\n",
    "            label_key: [class_name] * len(paragraphs),\n",
    "            class_key: class_count\n",
    "        })], ignore_index=True)\n",
    "        label_list.append(book_key)\n",
    "        class_count += 1\n",
    "    logger.info(\n",
    "        f'\\nsample of output data:\\n{data.sample(random_state=random_state, n=5)}')\n",
    "    return data, label_list\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    clean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-24 17:22:28.974 | INFO     | utils:get_glob:17 - getting files using glob\n",
      "2020-09-24 17:22:28.976 | INFO     | __main__:clean:40 - processing austen\n",
      "2020-09-24 17:22:28.976 | INFO     | __main__:clean:66 - title: the complete project gutenberg works of jane austen\n",
      "2020-09-24 17:22:28.977 | INFO     | __main__:clean:69 - author: jane austen\n",
      "2020-09-24 17:22:29.022 | INFO     | __main__:clean:86 - number of paragraphs in class \"Jane Austen\": 2497\n",
      "2020-09-24 17:22:29.026 | INFO     | __main__:clean:40 - processing dostoyevsky\n",
      "2020-09-24 17:22:29.027 | INFO     | __main__:clean:66 - title: the brothers karamazov\n",
      "2020-09-24 17:22:29.028 | INFO     | __main__:clean:69 - author: fyodor dostoyevsky\n",
      "2020-09-24 17:22:29.086 | INFO     | __main__:clean:86 - number of paragraphs in class \"Fyodor Dostoyevsky\": 5840\n",
      "2020-09-24 17:22:29.092 | INFO     | __main__:clean:40 - processing doyle\n",
      "2020-09-24 17:22:29.094 | INFO     | __main__:clean:66 - title: the adventures of sherlock holmes\n",
      "2020-09-24 17:22:29.094 | INFO     | __main__:clean:69 - author: arthur conan doyle\n",
      "2020-09-24 17:22:29.110 | INFO     | __main__:clean:86 - number of paragraphs in class \"Arthur Conan Doyle\": 581\n",
      "2020-09-24 17:22:29.116 | INFO     | __main__:clean:95 - \n",
      "sample of output data:\n",
      "                                              paragraph               label  \\\n",
      "1132  the succeeding morning promised something bett...         Jane Austen   \n",
      "7143  mitya shrugged his shoulders nervously and sho...  Fyodor Dostoyevsky   \n",
      "5413  mitya immediately stared at kalganov and then ...  Fyodor Dostoyevsky   \n",
      "8468  a professional case of great gravity was engag...  Arthur Conan Doyle   \n",
      "4637  “casting out i cast out!” and, turning in all ...  Fyodor Dostoyevsky   \n",
      "\n",
      "      class  \n",
      "1132      0  \n",
      "7143      1  \n",
      "5413      1  \n",
      "8468      2  \n",
      "4637      1  \n"
     ]
    }
   ],
   "source": [
    "clean_data, label_list = clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two different types of logistic regression algorithms that were required for this assignment - mini-batch gradient descent logistic regression, and stochastic gradient descent logistic regression. In my first implementation of the logistic regression algorithm, I mistakenly used batch gradient descent, thinking that it would easily translate to mini-batch. Unfortunately, the specific implementation I used, while very efficient, is difficult to port to mini-batch. This is because I used a minimization function - \"bfgs\" to be specific, to minimize the loss. Using the minimization function requires a different gradient function than for mini-batch. Therefore, I needed to create a completely different implementation to actually complete this assignment. The batch version is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "minibatch logistic regression\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "# from loguru import logger\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# relative imports\n",
    "#from books import start_end_map\n",
    "\n",
    "\n",
    "def softmax(x, multi=True):\n",
    "    \"\"\"\n",
    "    get the softmax\n",
    "    \"\"\"\n",
    "    ex = np.exp(x - np.max(x))\n",
    "    return ex / ex.sum(axis=1 if multi else 0)\n",
    "\n",
    "\n",
    "def _process_labels(y_train):\n",
    "    \"\"\"\n",
    "    process labels to array\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for val in y_train:\n",
    "        res.append(np.zeros(3))\n",
    "        res[-1][val] = 1\n",
    "    return np.array(res)\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    logistic regression\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epochs=100, batch_size=32, lmbda=1e-4, plot_epoch_iter=1, **_args):\n",
    "        \"\"\"\n",
    "        logistic regression init\n",
    "        \"\"\"\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias_matrix = None\n",
    "        self.batch_size = batch_size\n",
    "        self.lmbda = lmbda\n",
    "        self.bias_vector = None\n",
    "        self.plot_epoch_iter = plot_epoch_iter\n",
    "        self.training_scores = None\n",
    "        self.testing_scores = None\n",
    "\n",
    "    def _regularization(self, index, k):\n",
    "        return self.lmbda * (self.weights[index, k]**2)\n",
    "\n",
    "    def _regularization_gradient(self, k):\n",
    "        return 2 * self.lmbda * self.weights[:, k]\n",
    "\n",
    "    def _net(self, Xi, multi=True):\n",
    "        \"\"\"\n",
    "        Define out network and obtain a predicted output for a set of M inputs ( V > K )\n",
    "        \"\"\"\n",
    "        y_linear = np.add(np.dot(Xi, self.weights), self.bias_vector[0])\n",
    "        return softmax(y_linear, multi=multi)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        returns the accuracy score of the logistic regression function\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return accuracy_score(y, self.predict(X))\n",
    "        except ValueError:\n",
    "            return 0.\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        get prediction for given array of inputs\n",
    "        \"\"\"\n",
    "        X = X.toarray()\n",
    "        res = []\n",
    "        for elem in X:\n",
    "            net_output = self._net(elem, multi=False)\n",
    "            output = np.argmax(net_output[0])\n",
    "            res.append(output)\n",
    "        return res\n",
    "\n",
    "    def fit(self, X_train_text, y_train, X_test_text, y_test):\n",
    "        \"\"\"\n",
    "        main training loop\n",
    "        \"\"\"\n",
    "        X_train = X_train_text\n",
    "        X_train_text = X_train_text.toarray()\n",
    "        y_train = _process_labels(y_train)\n",
    "        N = X_train_text.shape[0]  # dataset length\n",
    "        V = X_train_text.shape[1]  # vocabulary length\n",
    "        K = len(start_end_map.keys()) # num of classes\n",
    "        lr = 1e-2  # Learning rate\n",
    "        self.weights = np.random.rand(V, K) # weight vector\n",
    "        self.bias_vector = np.random.rand(1, K) # bias vector\n",
    "        self.bias_matrix = np.repeat(\n",
    "            self.bias_vector, self.batch_size, axis=0) # bias matrix\n",
    "\n",
    "        dataset_len = X_train_text.shape[0]\n",
    "        dataset_indexes = np.arange(dataset_len)\n",
    "        training_scores = []\n",
    "        testing_scores = []\n",
    "        for epoch in range(self.epochs):\n",
    "            # logger.info(f\"Epoch: {epoch + 1}\")\n",
    "            epoch_loss = 0\n",
    "            epoch_gradient = np.zeros((V, K))\n",
    "            for _batch_index in range(0, N, self.batch_size):\n",
    "                current_indices = np.random.choice(\n",
    "                    dataset_indexes, self.batch_size, replace=False)\n",
    "                X = X_train_text[current_indices]\n",
    "                Y = y_train[current_indices]\n",
    "                for index, Xi, Yi in zip(current_indices, X, Y):\n",
    "                    Xi = Xi.reshape(1, V)\n",
    "                    Yi = Yi.reshape(1, K)\n",
    "                    yhat = self._net(Xi, multi=(\n",
    "                        self.batch_size != 1)).reshape(1, K)\n",
    "                    k_true = np.where(Yi[0] == 1)\n",
    "                    # Prediction component of loss update\n",
    "                    epoch_loss += -(1/N) * (np.dot(np.transpose(Yi), yhat))\n",
    "                    # Prediction component of epoch gradient update\n",
    "                    a = (np.transpose(Xi) @ (1-yhat))[:, k_true]\n",
    "                    epoch_gradient[:,\n",
    "                                   k_true] += a\n",
    "                    # for all classes\n",
    "                    for k in range(K):\n",
    "                        # regularization update per class\n",
    "                        epoch_loss += self._regularization(index, k)\n",
    "                        epoch_gradient[:,\n",
    "                                       k] += self._regularization_gradient(k)\n",
    "            if (epoch + 1) % self.plot_epoch_iter == 0:\n",
    "                training_scores.append(\n",
    "                    self.score(X_train, y_train))\n",
    "                testing_scores.append(\n",
    "                    self.score(X_test_text, y_test))\n",
    "            self.weights = self.weights - lr * epoch_gradient\n",
    "        self.training_scores = training_scores\n",
    "        self.testing_scores = testing_scores\n",
    "\n",
    "    def get_train_test_scores(self):\n",
    "        \"\"\"\n",
    "        get training and testing score data (for plotting)\n",
    "        \"\"\"\n",
    "        return self.training_scores, self.testing_scores\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    raise RuntimeError(\"logistic regression cannot be run on its own\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final version of the logistic regression algorithm is shown below. In this version, I am not using a minimization function at all. Instead, I am using a learning rate with an iterative approach to handle the weight updates. The softmax, regularization, and regularization_gradient functions are all defined in the class function, so that they can access the object's current weights and working variables. This does not use any outside packages besides numpy, loguru (a logging library), and `accuracy_score` from scikit learn for validation. The main training loop is found in fit, and there is a getter for the training and testing scores that are produced during the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "minibatch logistic regression\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "# from loguru import logger\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# relative imports\n",
    "#from books import start_end_map\n",
    "\n",
    "\n",
    "def softmax(x, multi=True):\n",
    "    \"\"\"\n",
    "    get the softmax\n",
    "    \"\"\"\n",
    "    ex = np.exp(x - np.max(x))\n",
    "    return ex / ex.sum(axis=1 if multi else 0)\n",
    "\n",
    "\n",
    "def _process_labels(y_train):\n",
    "    \"\"\"\n",
    "    process labels to array\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for val in y_train:\n",
    "        res.append(np.zeros(3))\n",
    "        res[-1][val] = 1\n",
    "    return np.array(res)\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    logistic regression\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epochs=100, batch_size=32, lmbda=1e-4, plot_epoch_iter=1, **_args):\n",
    "        \"\"\"\n",
    "        logistic regression init\n",
    "        \"\"\"\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias_matrix = None\n",
    "        self.batch_size = batch_size\n",
    "        self.lmbda = lmbda\n",
    "        self.bias_vector = None\n",
    "        self.plot_epoch_iter = plot_epoch_iter\n",
    "        self.training_scores = None\n",
    "        self.testing_scores = None\n",
    "\n",
    "    def _regularization(self, index, k):\n",
    "        return self.lmbda * (self.weights[index, k]**2)\n",
    "\n",
    "    def _regularization_gradient(self, k):\n",
    "        return 2 * self.lmbda * self.weights[:, k]\n",
    "\n",
    "    def _net(self, Xi, multi=True):\n",
    "        \"\"\"\n",
    "        Define out network and obtain a predicted output for a set of M inputs ( V > K )\n",
    "        \"\"\"\n",
    "        y_linear = np.add(np.dot(Xi, self.weights), self.bias_vector[0])\n",
    "        return softmax(y_linear, multi=multi)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        returns the accuracy score of the logistic regression function\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return accuracy_score(y, self.predict(X))\n",
    "        except ValueError:\n",
    "            return 0.\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        get prediction for given array of inputs\n",
    "        \"\"\"\n",
    "        X = X.toarray()\n",
    "        res = []\n",
    "        for elem in X:\n",
    "            net_output = self._net(elem, multi=False)\n",
    "            output = np.argmax(net_output[0])\n",
    "            res.append(output)\n",
    "        return res\n",
    "\n",
    "    def fit(self, X_train_text, y_train, X_test_text, y_test):\n",
    "        \"\"\"\n",
    "        main training loop\n",
    "        \"\"\"\n",
    "        X_train = X_train_text\n",
    "        X_train_text = X_train_text.toarray()\n",
    "        y_train = _process_labels(y_train)\n",
    "        N = X_train_text.shape[0]  # dataset length\n",
    "        V = X_train_text.shape[1]  # vocabulary length\n",
    "        K = len(start_end_map.keys()) # num of classes\n",
    "        lr = 1e-2  # Learning rate\n",
    "        self.weights = np.random.rand(V, K) # weight vector\n",
    "        self.bias_vector = np.random.rand(1, K) # bias vector\n",
    "        self.bias_matrix = np.repeat(\n",
    "            self.bias_vector, self.batch_size, axis=0) # bias matrix\n",
    "\n",
    "        dataset_len = X_train_text.shape[0]\n",
    "        dataset_indexes = np.arange(dataset_len)\n",
    "        training_scores = []\n",
    "        testing_scores = []\n",
    "        for epoch in range(self.epochs):\n",
    "            # logger.info(f\"Epoch: {epoch + 1}\")\n",
    "            epoch_loss = 0\n",
    "            epoch_gradient = np.zeros((V, K))\n",
    "            for _batch_index in range(0, N, self.batch_size):\n",
    "                current_indices = np.random.choice(\n",
    "                    dataset_indexes, self.batch_size, replace=False)\n",
    "                X = X_train_text[current_indices]\n",
    "                Y = y_train[current_indices]\n",
    "                for index, Xi, Yi in zip(current_indices, X, Y):\n",
    "                    Xi = Xi.reshape(1, V)\n",
    "                    Yi = Yi.reshape(1, K)\n",
    "                    yhat = self._net(Xi, multi=(\n",
    "                        self.batch_size != 1)).reshape(1, K)\n",
    "                    k_true = np.where(Yi[0] == 1)\n",
    "                    # Prediction component of loss update\n",
    "                    epoch_loss += -(1/N) * (np.dot(np.transpose(Yi), yhat))\n",
    "                    # Prediction component of epoch gradient update\n",
    "                    a = (np.transpose(Xi) @ (1-yhat))[:, k_true]\n",
    "                    epoch_gradient[:,\n",
    "                                   k_true] += a\n",
    "                    # for all classes\n",
    "                    for k in range(K):\n",
    "                        # regularization update per class\n",
    "                        epoch_loss += self._regularization(index, k)\n",
    "                        epoch_gradient[:,\n",
    "                                       k] += self._regularization_gradient(k)\n",
    "            if (epoch + 1) % self.plot_epoch_iter == 0:\n",
    "                training_scores.append(\n",
    "                    self.score(X_train, y_train))\n",
    "                testing_scores.append(\n",
    "                    self.score(X_test_text, y_test))\n",
    "            self.weights = self.weights - lr * epoch_gradient\n",
    "        self.training_scores = training_scores\n",
    "        self.testing_scores = testing_scores\n",
    "\n",
    "    def get_train_test_scores(self):\n",
    "        \"\"\"\n",
    "        get training and testing score data (for plotting)\n",
    "        \"\"\"\n",
    "        return self.training_scores, self.testing_scores\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    raise RuntimeError(\"logistic regression cannot be run on its own\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the main training loop, the train function takes an input of the clean data dataframe, and a list of BookType enums with indexes corresponding to the class numbers in the dataframe. The first step is to initialize all the variables and objects that will be used in the loop. `StratifiedKFold` is used to split the training data into training and testing data in K Folds, and the `train_test_split` function is used to split the overall dataset into training and testing data beforehand. The clean paragraph text is converted into vectors using the `TfidfVectorizer` object, which is fitted over only the training data (as opposed to the entire corpus). Once this data is vectorized, it is ready for the training loop.\n",
    "\n",
    "The main loop iterates over the K Folds in the training data. First, the unnecessary `BatchLogisticRegression` trains to give a reference to the other classification methods. Next, the options for lambda in the logistic regression are iterated over, used for training both the minibatch and sgd logistic regression classifiers. The best scoring model over all iterations of the outer loop is saved, along with its training and validation scores.\n",
    "\n",
    "In the second inner for loop, the iteration is done over the hidden layers possible for the MLP model. Currently it is set for a single layer of 2, 3, or 4 neurons. `partial_fit` was used instead of `fit` because the scores at the end of each epoch were required for plotting the loss curves. Again, the best mlp model is saved for later analysis. The parameters are defined explicitly for the MLP model before the training loop, including the learning rate, optimizer, and network structure. The loss function cannot be changed due to the implementation of the scikit learn MLP library, and is by default log-loss.\n",
    "\n",
    "At the end of the training loop, the training loss and validation loss curves are plotted using `matplotlib` for the minibatch and stochastic gradient descent logistic regressions, and for the multi-layer perceptron model. Next, the classification report is outputted for each of the models, which computes the precision, recall, and accuracy. Finally, the best lambdas (for the logistic regressions), and the best number of neurons in the hidden layer (for the MLP) are outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "training (train.py)\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Optional\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from variables import paragraph_key, class_key, random_state\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# relative imports:\n",
    "#from books import class_map, BookType\n",
    "#from logit import LogisticRegression as LogisticRegression\n",
    "#from batch_logistic_regression import BatchLogisticRegression\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "NUM_EPOCHS = 100\n",
    "PLOT_EPOCH_ITER = 1\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "assert NUM_EPOCHS >= PLOT_EPOCH_ITER, 'number of epochs must be greater than plot iter'\n",
    "\n",
    "\n",
    "def one_minus(data: List[float]) -> List[float]:\n",
    "    \"\"\"\n",
    "    return 1 - each element in list\n",
    "    \"\"\"\n",
    "    return list(map(lambda elem: 1 - elem, data))\n",
    "\n",
    "\n",
    "def train(clean_data: pd.DataFrame, label_list: List[BookType]) -> None:\n",
    "    \"\"\"\n",
    "    the main training function. also produces graphs and visualizations.\n",
    "    \"\"\"\n",
    "    logger.info('start test train split')\n",
    "    num_classes: int = len(class_map.keys())\n",
    "    classes = range(num_classes)\n",
    "    num_splits: int = num_classes + 1\n",
    "    # using stratified instead of random split because this is a classification problem,\n",
    "    # where we want to have an even distribution of samples from each class in the training\n",
    "    # and testing data\n",
    "    skf = StratifiedKFold(n_splits=num_splits,\n",
    "                          shuffle=True, random_state=random_state)\n",
    "\n",
    "    lambda_options: List[float] = [1, 2, 3]\n",
    "\n",
    "    # for minibatch\n",
    "    best_minibatch_logit_score: float = 0.0\n",
    "    best_minibatch_logit: Optional[LogisticRegression] = None\n",
    "    best_minibatch_logit_lambda: Optional[int] = None\n",
    "    best_minibatch_logit_training_scores: Optional[List[float]] = None\n",
    "    best_minibatch_logit_validation_scores: Optional[List[float]] = None\n",
    "\n",
    "    # for sgd\n",
    "    best_sgd_logit_score: float = 0.0\n",
    "    best_sgd_logit: Optional[LogisticRegression] = None\n",
    "    best_sgd_logit_lambda: Optional[int] = None\n",
    "    best_sgd_logit_training_scores: Optional[List[float]] = None\n",
    "    best_sgd_logit_validation_scores: Optional[List[float]] = None\n",
    "\n",
    "    # by default, the mlp loss function is log_loss\n",
    "    optimizer: str = 'adam'\n",
    "    learning_rate: float = 0.001\n",
    "    hidden_layer_options: List[List[int]] = [[3], [2]]\n",
    "    best_hidden_layers: Optional[List[float]] = None\n",
    "    best_mlp_training_scores: Optional[List[float]] = None\n",
    "    best_mlp_testing_scores: Optional[List[float]] = None\n",
    "    best_mlp: Optional[MLPClassifier] = None\n",
    "    best_mlp_score: float = 0.0\n",
    "\n",
    "    text_transformer = TfidfVectorizer(\n",
    "        stop_words='english', lowercase=True, max_features=150000)\n",
    "\n",
    "    all_X = clean_data[paragraph_key].values\n",
    "    all_y = clean_data[class_key].values\n",
    "\n",
    "    X, all_X_test, y, all_y_test = train_test_split(\n",
    "        all_X, all_y, random_state=random_state, test_size=TEST_SIZE)\n",
    "\n",
    "    # Data Split\n",
    "    data_split = tuple(skf.split(X, y))\n",
    "\n",
    "    # tf idf fit\n",
    "    all_X_train: List[str] = []\n",
    "    for train_index, _ in data_split:\n",
    "        all_X_train.extend(X[train_index])\n",
    "    text_transformer.fit(all_X_train)\n",
    "    del all_X_train\n",
    "\n",
    "    for train_index, test_index in data_split:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        logger.info('test train split complete')\n",
    "\n",
    "        # Feature Extraction\n",
    "        logger.info('start text transform')\n",
    "        X_train_text = text_transformer.transform(X_train)\n",
    "        X_test_text = text_transformer.transform(X_test)\n",
    "        logger.info('text transformed')\n",
    "\n",
    "        # Train classifiers\n",
    "\n",
    "        # batch logistic regression\n",
    "        batch_logit = BatchLogisticRegression()\n",
    "        batch_logit.fit(X_train_text, y_train)\n",
    "        logger.info(f'logistic regression batch testing score: {batch_logit.score(X_test_text, y_test)}')\n",
    "\n",
    "        # logistic regressions\n",
    "        for current_lambda in lambda_options:\n",
    "            logger.info(f'starting logistic regression training with lambda {current_lambda}')\n",
    "\n",
    "            logger.info('logistic regression mini-batch:')\n",
    "            logger.info('start logistic regression mini-batch fit')\n",
    "            minibatch_logit = LogisticRegression(\n",
    "                lmbda=current_lambda, plot_epoch_iter=PLOT_EPOCH_ITER, batch_size=BATCH_SIZE)\n",
    "            minibatch_logit.fit(X_train_text, y_train, X_test_text, y_test)\n",
    "            current_minibatch_logit_training_scores, current_minibatch_logit_validation_scores = \\\n",
    "                minibatch_logit.get_train_test_scores()\n",
    "            logger.info('done with logistic regression mini batch train fit')\n",
    "            current_minibatch_logit_score = minibatch_logit.score(X_test_text, y_test)\n",
    "            if current_minibatch_logit_score >= best_minibatch_logit_score:\n",
    "                best_minibatch_logit_score = current_minibatch_logit_score\n",
    "                best_minibatch_logit = minibatch_logit\n",
    "                best_minibatch_logit_lambda = current_lambda\n",
    "                best_minibatch_logit_training_scores = current_minibatch_logit_training_scores\n",
    "                best_minibatch_logit_validation_scores = current_minibatch_logit_validation_scores\n",
    "            logger.info(\n",
    "                f'logistic regression mini batch testing score: {current_minibatch_logit_score}')\n",
    "\n",
    "            logger.info('logistic regression sgd:')\n",
    "            logger.info('start logistic regression sgd fit')\n",
    "            # same LogisticRegression algorithm, but the batch size is now 1\n",
    "            sgd_logit = LogisticRegression(\n",
    "              lmbda=current_lambda, plot_epoch_iter=PLOT_EPOCH_ITER, batch_size=1)\n",
    "            sgd_logit.fit(X_train_text, y_train, X_test_text, y_test)\n",
    "            current_sgd_logit_training_scores, current_sgd_logit_validation_scores = \\\n",
    "                sgd_logit.get_train_test_scores()\n",
    "            logger.info('done with logistic regression sgd train fit')\n",
    "            current_sgd_logit_score = sgd_logit.score(X_test_text, y_test)\n",
    "            if current_sgd_logit_score >= best_sgd_logit_score:\n",
    "                best_sgd_logit_score = current_sgd_logit_score\n",
    "                best_sgd_logit = sgd_logit\n",
    "                best_sgd_logit_lambda = current_lambda\n",
    "                best_sgd_logit_training_scores = current_sgd_logit_training_scores\n",
    "                best_sgd_logit_validation_scores = current_sgd_logit_validation_scores\n",
    "            logger.info(\n",
    "                f'logistic regression sgd testing score: {current_sgd_logit_score}')\n",
    "\n",
    "        logger.info('multi layer perceptron:')\n",
    "        logger.info('start mlp classifier fit')\n",
    "        num_training_samples = X_train_text.shape[0]\n",
    "        for hidden_layers in hidden_layer_options:\n",
    "            current_mlp_training_scores = []\n",
    "            current_mlp_testing_scores = []\n",
    "            logger.info(f'mlp for hidden layer {hidden_layers}')\n",
    "            mlp = MLPClassifier(random_state=random_state,\n",
    "                                hidden_layer_sizes=list(hidden_layers), verbose=False,\n",
    "                                learning_rate='constant', learning_rate_init=learning_rate,\n",
    "                                solver=optimizer)\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                # logger.info(f'epoch {epoch + 1}')\n",
    "                random_perm = np.random.permutation(num_training_samples)\n",
    "                for start_index in range(0, num_training_samples, BATCH_SIZE):\n",
    "                    current_indices = random_perm[start_index: start_index +\n",
    "                                                  BATCH_SIZE].tolist()\n",
    "                    mlp.partial_fit(\n",
    "                        X_train_text[current_indices], y_train[current_indices],\n",
    "                        classes=classes)\n",
    "                if (epoch + 1) % PLOT_EPOCH_ITER == 0:\n",
    "                    current_mlp_training_scores.append(\n",
    "                        mlp.score(X_train_text, y_train))\n",
    "                    current_mlp_testing_scores.append(\n",
    "                        mlp.score(X_test_text, y_test))\n",
    "            current_mlp_score = current_mlp_testing_scores[-1]\n",
    "            logger.info(f'mlp testing score: {current_mlp_score}')\n",
    "            if current_mlp_score >= best_mlp_score:\n",
    "                best_mlp_score = current_mlp_score\n",
    "                best_mlp_testing_scores = current_mlp_testing_scores\n",
    "                best_mlp_training_scores = current_mlp_training_scores\n",
    "                best_mlp = mlp\n",
    "                best_hidden_layers = hidden_layers\n",
    "\n",
    "    # PLOT for logistic regression\n",
    "    fig, ax = plt.subplots(2, sharex=True, sharey=True)\n",
    "    ax[0].plot(best_minibatch_logit_training_scores)\n",
    "    ax[0].set_title('Training Loss')\n",
    "    ax[1].plot(best_minibatch_logit_validation_scores)\n",
    "    ax[1].set_title('Validation Loss')\n",
    "    fig.suptitle(\n",
    "        f'Best MiniBatch Logistic Regression Training and Validation Loss over {NUM_EPOCHS} ' +\n",
    "        f\"epoch{'' if PLOT_EPOCH_ITER == 1 else 's'}\",\n",
    "        fontsize=14)\n",
    "\n",
    "    fig, ax = plt.subplots(2, sharex=True, sharey=True)\n",
    "    ax[0].plot(best_sgd_logit_training_scores)\n",
    "    ax[0].set_title('Training Loss')\n",
    "    ax[1].plot(best_sgd_logit_validation_scores)\n",
    "    ax[1].set_title('Validation Loss')\n",
    "    fig.suptitle(\n",
    "        f'Best SGD Logistic Regression Training and Validation Loss over {NUM_EPOCHS} ' +\n",
    "        f\"epoch{'' if PLOT_EPOCH_ITER == 1 else 's'}\",\n",
    "        fontsize=14)\n",
    "\n",
    "    # PLOT training loss and validation loss\n",
    "    fig, ax = plt.subplots(2, sharex=True, sharey=True)\n",
    "    ax[0].plot(one_minus(best_mlp_training_scores))\n",
    "    ax[0].set_title('Training Loss')\n",
    "    ax[1].plot(one_minus(best_mlp_testing_scores))\n",
    "    ax[1].set_title('Validation Loss')\n",
    "    fig.suptitle(\n",
    "        f'Best MLP Training and Validation Loss over {NUM_EPOCHS} ' +\n",
    "        f\"epoch{'' if PLOT_EPOCH_ITER == 1 else 's'}\",\n",
    "        fontsize=14)\n",
    "\n",
    "    # Feature Extraction\n",
    "    logger.info('start text transform')\n",
    "    all_X_test_text = text_transformer.transform(all_X_test)\n",
    "    logger.info('text transformed')\n",
    "    class_labels = [class_map[book_type] for book_type in label_list]\n",
    "\n",
    "    batch_logit_predict = best_minibatch_logit.predict(all_X_test_text)\n",
    "    performance = classification_report(\n",
    "        all_y_test, batch_logit_predict, target_names=class_labels)\n",
    "    logger.info(f'\\nperformance for minibatch logistic regression:\\n{performance}')\n",
    "    logger.success(\n",
    "        f'best minibatch logistic regression lambda: {best_minibatch_logit_lambda}')\n",
    "\n",
    "    sgd_logit_predict = best_sgd_logit.predict(all_X_test_text)\n",
    "    performance = classification_report(\n",
    "        all_y_test, sgd_logit_predict, target_names=class_labels)\n",
    "    logger.info(f'\\nperformance for sgd logistic regression:\\n{performance}')\n",
    "    logger.success(\n",
    "        f'best sgd logistic regression lambda: {best_sgd_logit_lambda}')\n",
    "\n",
    "    mlp_predict = best_mlp.predict(all_X_test_text)\n",
    "    performance = classification_report(\n",
    "        all_y_test, mlp_predict, target_names=class_labels)\n",
    "    logger.info(f'\\nperformance for mlp:\\n{performance}')\n",
    "    logger.success(\n",
    "        f'best number of neurons in hidden layer of mlp: {best_hidden_layers[0]}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    raise RuntimeError(\"training cannot be run on its own\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are shown below. You may need to expand the side to view all of the lines, as there are many logging statements. At the bottom you will find all of the outputted graphs, along with the performance metrics that answer all of the individual questions for cross-validation, best number of neurons in hidden layer, best lambda value, the overall scores / performance of each model, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-24 17:29:21.377 | INFO     | __main__:train:50 - start test train split\n",
      "2020-09-24 17:29:22.377 | INFO     | __main__:train:108 - test train split complete\n",
      "2020-09-24 17:29:22.377 | INFO     | __main__:train:111 - start text transform\n",
      "2020-09-24 17:29:22.736 | INFO     | __main__:train:114 - text transformed\n",
      "2020-09-24 17:29:23.764 | INFO     | __main__:train:121 - logistic regression batch testing score: 0.9389013452914798\n",
      "2020-09-24 17:29:23.765 | INFO     | __main__:train:125 - starting logistic regression training with lambda 1\n",
      "2020-09-24 17:29:23.765 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:29:23.766 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:29:24.634 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:29:24.636 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9389013452914798\n",
      "2020-09-24 17:29:24.637 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:29:24.638 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:29:24.714 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:29:24.716 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9646860986547086\n",
      "2020-09-24 17:29:24.717 | INFO     | __main__:train:125 - starting logistic regression training with lambda 2\n",
      "2020-09-24 17:29:24.718 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:29:24.718 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:29:26.157 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:29:26.159 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9489910313901345\n",
      "2020-09-24 17:29:26.162 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:29:26.169 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:29:26.245 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:29:26.247 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9646860986547086\n",
      "2020-09-24 17:29:26.248 | INFO     | __main__:train:125 - starting logistic regression training with lambda 3\n",
      "2020-09-24 17:29:26.249 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:29:26.249 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:29:27.886 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:29:27.891 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9562780269058296\n",
      "2020-09-24 17:29:27.891 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:29:27.892 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:29:28.044 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:29:28.045 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9646860986547086\n",
      "2020-09-24 17:29:28.046 | INFO     | __main__:train:125 - starting logistic regression training with lambda 4\n",
      "2020-09-24 17:29:28.047 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:29:28.047 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:29:29.444 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:29:29.446 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9573991031390134\n",
      "2020-09-24 17:29:29.446 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:29:29.447 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:29:29.521 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:29:29.523 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9646860986547086\n",
      "2020-09-24 17:29:29.529 | INFO     | __main__:train:169 - multi layer perceptron:\n",
      "2020-09-24 17:29:29.530 | INFO     | __main__:train:170 - start mlp classifier fit\n",
      "2020-09-24 17:29:29.533 | INFO     | __main__:train:175 - mlp for hidden layer [2]\n",
      "2020-09-24 17:29:47.498 | INFO     | __main__:train:195 - mlp testing score: 0.9551569506726457\n",
      "2020-09-24 17:29:47.499 | INFO     | __main__:train:175 - mlp for hidden layer [3]\n",
      "2020-09-24 17:30:05.514 | INFO     | __main__:train:195 - mlp testing score: 0.968609865470852\n",
      "2020-09-24 17:30:05.516 | INFO     | __main__:train:175 - mlp for hidden layer [4]\n",
      "2020-09-24 17:30:22.707 | INFO     | __main__:train:195 - mlp testing score: 0.9669282511210763\n",
      "2020-09-24 17:30:22.709 | INFO     | __main__:train:108 - test train split complete\n",
      "2020-09-24 17:30:22.720 | INFO     | __main__:train:111 - start text transform\n",
      "2020-09-24 17:30:23.094 | INFO     | __main__:train:114 - text transformed\n",
      "2020-09-24 17:30:23.949 | INFO     | __main__:train:121 - logistic regression batch testing score: 0.9316143497757847\n",
      "2020-09-24 17:30:23.950 | INFO     | __main__:train:125 - starting logistic regression training with lambda 1\n",
      "2020-09-24 17:30:23.951 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:30:23.951 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:30:24.878 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:30:24.880 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9316143497757847\n",
      "2020-09-24 17:30:24.881 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:30:24.881 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:30:24.982 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:30:24.985 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9602017937219731\n",
      "2020-09-24 17:30:24.986 | INFO     | __main__:train:125 - starting logistic regression training with lambda 2\n",
      "2020-09-24 17:30:24.989 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:30:24.992 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:30:26.165 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:30:26.168 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9411434977578476\n",
      "2020-09-24 17:30:26.169 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:30:26.176 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:30:26.274 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:30:26.277 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9602017937219731\n",
      "2020-09-24 17:30:26.279 | INFO     | __main__:train:125 - starting logistic regression training with lambda 3\n",
      "2020-09-24 17:30:26.284 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:30:26.285 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:30:27.467 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:30:27.469 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.945627802690583\n",
      "2020-09-24 17:30:27.480 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:30:27.480 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:30:27.573 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:30:27.576 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9602017937219731\n",
      "2020-09-24 17:30:27.577 | INFO     | __main__:train:125 - starting logistic regression training with lambda 4\n",
      "2020-09-24 17:30:27.580 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:30:27.581 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-24 17:30:29.212 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:30:29.214 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9484304932735426\n",
      "2020-09-24 17:30:29.214 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:30:29.215 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:30:29.310 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:30:29.312 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9602017937219731\n",
      "2020-09-24 17:30:29.314 | INFO     | __main__:train:169 - multi layer perceptron:\n",
      "2020-09-24 17:30:29.320 | INFO     | __main__:train:170 - start mlp classifier fit\n",
      "2020-09-24 17:30:29.321 | INFO     | __main__:train:175 - mlp for hidden layer [2]\n",
      "2020-09-24 17:30:45.702 | INFO     | __main__:train:195 - mlp testing score: 0.9439461883408071\n",
      "2020-09-24 17:30:45.705 | INFO     | __main__:train:175 - mlp for hidden layer [3]\n",
      "2020-09-24 17:31:01.949 | INFO     | __main__:train:195 - mlp testing score: 0.9635650224215246\n",
      "2020-09-24 17:31:01.951 | INFO     | __main__:train:175 - mlp for hidden layer [4]\n",
      "2020-09-24 17:31:19.230 | INFO     | __main__:train:195 - mlp testing score: 0.9596412556053812\n",
      "2020-09-24 17:31:19.231 | INFO     | __main__:train:108 - test train split complete\n",
      "2020-09-24 17:31:19.234 | INFO     | __main__:train:111 - start text transform\n",
      "2020-09-24 17:31:19.592 | INFO     | __main__:train:114 - text transformed\n",
      "2020-09-24 17:31:20.320 | INFO     | __main__:train:121 - logistic regression batch testing score: 0.9427930454290522\n",
      "2020-09-24 17:31:20.321 | INFO     | __main__:train:125 - starting logistic regression training with lambda 1\n",
      "2020-09-24 17:31:20.322 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:31:20.322 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:31:21.077 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:31:21.079 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9427930454290522\n",
      "2020-09-24 17:31:21.079 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:31:21.080 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:31:21.162 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:31:21.165 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9624228827818284\n",
      "2020-09-24 17:31:21.166 | INFO     | __main__:train:125 - starting logistic regression training with lambda 2\n",
      "2020-09-24 17:31:21.172 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:31:21.172 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:31:22.234 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:31:22.236 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.950084127874369\n",
      "2020-09-24 17:31:22.236 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:31:22.242 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:31:22.312 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:31:22.315 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9624228827818284\n",
      "2020-09-24 17:31:22.316 | INFO     | __main__:train:125 - starting logistic regression training with lambda 3\n",
      "2020-09-24 17:31:22.318 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:31:22.320 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:31:23.669 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:31:23.674 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9528883903533371\n",
      "2020-09-24 17:31:23.679 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:31:23.682 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:31:23.775 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:31:23.778 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9624228827818284\n",
      "2020-09-24 17:31:23.778 | INFO     | __main__:train:125 - starting logistic regression training with lambda 4\n",
      "2020-09-24 17:31:23.780 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:31:23.780 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:31:25.213 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:31:25.215 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9556926528323051\n",
      "2020-09-24 17:31:25.215 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:31:25.216 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:31:25.288 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:31:25.291 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.9624228827818284\n",
      "2020-09-24 17:31:25.291 | INFO     | __main__:train:169 - multi layer perceptron:\n",
      "2020-09-24 17:31:25.292 | INFO     | __main__:train:170 - start mlp classifier fit\n",
      "2020-09-24 17:31:25.293 | INFO     | __main__:train:175 - mlp for hidden layer [2]\n",
      "2020-09-24 17:31:40.219 | INFO     | __main__:train:195 - mlp testing score: 0.950084127874369\n",
      "2020-09-24 17:31:40.220 | INFO     | __main__:train:175 - mlp for hidden layer [3]\n",
      "2020-09-24 17:31:54.410 | INFO     | __main__:train:195 - mlp testing score: 0.96578799775659\n",
      "2020-09-24 17:31:54.411 | INFO     | __main__:train:175 - mlp for hidden layer [4]\n",
      "2020-09-24 17:32:11.387 | INFO     | __main__:train:195 - mlp testing score: 0.9624228827818284\n",
      "2020-09-24 17:32:11.389 | INFO     | __main__:train:108 - test train split complete\n",
      "2020-09-24 17:32:11.397 | INFO     | __main__:train:111 - start text transform\n",
      "2020-09-24 17:32:11.761 | INFO     | __main__:train:114 - text transformed\n",
      "2020-09-24 17:32:12.653 | INFO     | __main__:train:121 - logistic regression batch testing score: 0.93157599551318\n",
      "2020-09-24 17:32:12.653 | INFO     | __main__:train:125 - starting logistic regression training with lambda 1\n",
      "2020-09-24 17:32:12.654 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:32:12.655 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:32:13.654 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:32:13.656 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.93157599551318\n",
      "2020-09-24 17:32:13.657 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:32:13.658 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:32:13.746 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:32:13.749 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.957375210319686\n",
      "2020-09-24 17:32:13.750 | INFO     | __main__:train:125 - starting logistic regression training with lambda 2\n",
      "2020-09-24 17:32:13.751 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:32:13.752 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:32:15.012 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:32:15.015 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9394279304542905\n",
      "2020-09-24 17:32:15.035 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:32:15.037 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:32:15.093 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:32:15.095 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.957375210319686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-24 17:32:15.096 | INFO     | __main__:train:125 - starting logistic regression training with lambda 3\n",
      "2020-09-24 17:32:15.097 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:32:15.097 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:32:16.596 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:32:16.599 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9416713404374649\n",
      "2020-09-24 17:32:16.600 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:32:16.600 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:32:16.681 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:32:16.686 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.957375210319686\n",
      "2020-09-24 17:32:16.691 | INFO     | __main__:train:125 - starting logistic regression training with lambda 4\n",
      "2020-09-24 17:32:16.691 | INFO     | __main__:train:127 - logistic regression mini-batch:\n",
      "2020-09-24 17:32:16.695 | INFO     | __main__:train:128 - start logistic regression mini-batch fit\n",
      "2020-09-24 17:32:18.182 | INFO     | __main__:train:134 - done with logistic regression mini batch train fit\n",
      "2020-09-24 17:32:18.185 | INFO     | __main__:train:142 - logistic regression mini batch testing score: 0.9427930454290522\n",
      "2020-09-24 17:32:18.186 | INFO     | __main__:train:145 - logistic regression sgd:\n",
      "2020-09-24 17:32:18.209 | INFO     | __main__:train:146 - start logistic regression sgd fit\n",
      "2020-09-24 17:32:18.291 | INFO     | __main__:train:158 - done with logistic regression sgd train fit\n",
      "2020-09-24 17:32:18.293 | INFO     | __main__:train:166 - logistic regression sgd testing score: 0.957375210319686\n",
      "2020-09-24 17:32:18.294 | INFO     | __main__:train:169 - multi layer perceptron:\n",
      "2020-09-24 17:32:18.295 | INFO     | __main__:train:170 - start mlp classifier fit\n",
      "2020-09-24 17:32:18.295 | INFO     | __main__:train:175 - mlp for hidden layer [2]\n",
      "2020-09-24 17:32:32.325 | INFO     | __main__:train:195 - mlp testing score: 0.9467190128996074\n",
      "2020-09-24 17:32:32.329 | INFO     | __main__:train:175 - mlp for hidden layer [3]\n",
      "2020-09-24 17:32:47.276 | INFO     | __main__:train:195 - mlp testing score: 0.9663488502523836\n",
      "2020-09-24 17:32:47.277 | INFO     | __main__:train:175 - mlp for hidden layer [4]\n",
      "2020-09-24 17:33:03.729 | INFO     | __main__:train:195 - mlp testing score: 0.9618620302860348\n",
      "2020-09-24 17:33:03.844 | INFO     | __main__:train:236 - start text transform\n",
      "2020-09-24 17:33:03.930 | INFO     | __main__:train:238 - text transformed\n",
      "2020-09-24 17:33:03.935 | INFO     | __main__:train:244 - \n",
      "performance for minibatch logistic regression:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       Jane Austen       0.99      0.91      0.95       496\n",
      "Fyodor Dostoyevsky       0.94      0.99      0.97      1186\n",
      "Arthur Conan Doyle       0.97      0.68      0.80       102\n",
      "\n",
      "          accuracy                           0.95      1784\n",
      "         macro avg       0.97      0.86      0.90      1784\n",
      "      weighted avg       0.96      0.95      0.95      1784\n",
      "\n",
      "2020-09-24 17:33:03.935 | SUCCESS  | __main__:train:245 - best minibatch logistic regression lambda: 4\n",
      "2020-09-24 17:33:03.941 | INFO     | __main__:train:251 - \n",
      "performance for sgd logistic regression:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       Jane Austen       0.97      0.94      0.95       496\n",
      "Fyodor Dostoyevsky       0.96      0.99      0.97      1186\n",
      "Arthur Conan Doyle       0.96      0.78      0.86       102\n",
      "\n",
      "          accuracy                           0.96      1784\n",
      "         macro avg       0.96      0.90      0.93      1784\n",
      "      weighted avg       0.96      0.96      0.96      1784\n",
      "\n",
      "2020-09-24 17:33:03.942 | SUCCESS  | __main__:train:252 - best sgd logistic regression lambda: 4\n",
      "2020-09-24 17:33:03.948 | INFO     | __main__:train:258 - \n",
      "performance for mlp:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       Jane Austen       0.97      0.95      0.96       496\n",
      "Fyodor Dostoyevsky       0.96      0.99      0.97      1186\n",
      "Arthur Conan Doyle       0.90      0.77      0.83       102\n",
      "\n",
      "          accuracy                           0.96      1784\n",
      "         macro avg       0.94      0.90      0.92      1784\n",
      "      weighted avg       0.96      0.96      0.96      1784\n",
      "\n",
      "2020-09-24 17:33:03.948 | SUCCESS  | __main__:train:259 - best number of neurons in hidden layer of mlp: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(clean_data, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, these models were fairly successful in classifying paragraphs of text into the three author categories provided. The accuracies for the sgd logistic regression and the mlp model were about the same, at 96%, with the minibatch logistic regression at 95%. The training was completed over 100 epochs. Looking at the loss graphs, it seems as though neither model needed to train for that many epochs. Maybe 20 or 25 epochs would have worked for optimal performance. Training for too many epochs may lead to overfitting for this given dataset, and it is unknown whether these results will translate to other books written by the same authors. Because the accuracies, precision, and recall were so high for both the MLP and Linear Regression models, I think it is safe to say that either model would work well for classifying these paragraphs. While the classification performance for `Jane Austen` and `Fyodor Dostoyevsky` were relatively high at around 95-96% for both models, the accuracy for `Arthur Conan Doyle` was lower at around 80-86%. This is probably due to only having 581 paragraph examples (see the output of the `clean` function), whereas the other two authors have 2497 and 5840 respectively. With more paragraph examples, I am sure that this accuracy will increase. The reason why there are less paragraph examples for `Arthur Conan Doyle` is because Sherlock Holmes has a lot of back-and-forth dialogue, which I attribute to one paragraph of text as opposed to multiple. If more complicated logic was implemented to split the text into shorter - but more accurate - paragraphs, there will be more paragraph examples for `Arthur Conan Doyle`, and most likely better model performance.\n",
    "\n",
    "In conclusion, both of these models performed well in classifying paragraphs between these three authors. More training data will almost certainly increase the overall performance of both models. It remains to be seen whether these models will perform well with completely unrelated texts written by the same authors (as opposed to within the same book), or if the models can distinguish between additional authors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}